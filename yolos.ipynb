{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Setup For Kaggle Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-07T09:56:43.609576Z",
     "iopub.status.busy": "2026-02-07T09:56:43.608958Z",
     "iopub.status.idle": "2026-02-07T09:56:43.628491Z",
     "shell.execute_reply": "2026-02-07T09:56:43.627771Z",
     "shell.execute_reply.started": "2026-02-07T09:56:43.609549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_INPUT = Path(\"/kaggle/input\")\n",
    "OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "print(\"content of /kaggle/input:\")\n",
    "for item in BASE_INPUT.iterdir():\n",
    "    tipo = \"DIR \" if item.is_dir() else \"FILE\"\n",
    "    print(f\" - [{tipo}] {item.name}\")\n",
    "\n",
    "#Search for \"data.yaml\"\n",
    "yaml_path = None\n",
    "for path in BASE_INPUT.rglob(\"data.yaml\"):\n",
    "    yaml_path = path\n",
    "    break\n",
    "\n",
    "if yaml_path is None:\n",
    "    print(\"\\n ERROR:: no 'data.yaml' found in /kaggle/input.\")\n",
    "    print(\"Check if your Roboflow dataset was correctly uploaded.\")\n",
    "else:\n",
    "     \n",
    "    DATA_DIR = yaml_path.parent\n",
    "\n",
    "    print(f\"\\n 'data.yaml' found: {yaml_path}\")\n",
    "    print(\"DATA_DIR:\", DATA_DIR)\n",
    "    print(\"OUTPUT_DIR           :\", OUTPUT_DIR)\n",
    "\n",
    "    print(\"\\n DATA_DIR content :\")\n",
    "    for item in DATA_DIR.iterdir():\n",
    "        tipo = \"DIR \" if item.is_dir() else \"FILE\"\n",
    "        print(f\" - [{tipo}] {item.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Dataset Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T09:56:46.052363Z",
     "iopub.status.busy": "2026-02-07T09:56:46.052026Z",
     "iopub.status.idle": "2026-02-07T09:57:18.888957Z",
     "shell.execute_reply": "2026-02-07T09:57:18.888274Z",
     "shell.execute_reply.started": "2026-02-07T09:56:46.052340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "#DATA_DIR check\n",
    "if \"DATA_DIR\" not in globals():\n",
    "    raise RuntimeError(\"DATA_DIR is not defined. Execute the first cell.\")\n",
    "\n",
    "data_dir = Path(DATA_DIR)\n",
    "yaml_file = data_dir / \"data.yaml\"\n",
    "\n",
    "if not yaml_file.exists():\n",
    "    yaml_file = None\n",
    "    for path in data_dir.rglob(\"data.yaml\"):\n",
    "        yaml_file = path\n",
    "        break\n",
    "\n",
    "if yaml_file is None or not yaml_file.exists():\n",
    "    print(\"Critical Error: 'data.yaml' not found in DATA_DIR.\")\n",
    "else:\n",
    "    print(f\"Using configuration file: {yaml_file}\")\n",
    "\n",
    "    with open(yaml_file, \"r\") as f:\n",
    "        data_cfg = yaml.safe_load(f)\n",
    "\n",
    "    print(\"\\n Principal Content of data.yaml:\")\n",
    "    for k in [\"path\", \"train\", \"val\", \"test\", \"nc\", \"names\"]:\n",
    "        if k in data_cfg:\n",
    "            print(f\" - {k}: {data_cfg[k]}\")\n",
    "\n",
    "    base_path = yaml_file.parent  #/kaggle/input/food-dataset\n",
    "\n",
    "    def find_images_dir(split_name, yaml_key):\n",
    "        \"\"\"\n",
    "        Finds the folder <split>/images looking in this order:\n",
    "        1) path said in data.yaml\n",
    "        2) base_path/<split_name>/images\n",
    "        3) recursive scan in base_path\n",
    "        \"\"\"\n",
    "        # 1) path said in data.yaml\n",
    "        p_str = data_cfg.get(yaml_key)\n",
    "        if p_str:\n",
    "            p = Path(p_str)\n",
    "            if not p.is_absolute():\n",
    "                p = (base_path / p).resolve()\n",
    "            if p.exists():\n",
    "                return p\n",
    "\n",
    "        # 2) base_path/<split_name>/images\n",
    "        candidate = base_path / split_name / \"images\"\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "\n",
    "        # 3) recursive scan in base_path\n",
    "        for img_dir in base_path.rglob(\"images\"):\n",
    "            if img_dir.parent.name == split_name:\n",
    "                return img_dir\n",
    "\n",
    "        return None\n",
    "\n",
    "    #Images folder\n",
    "    train_images_dir = find_images_dir(\"train\", \"train\")\n",
    "    val_images_dir   = find_images_dir(\"valid\", \"val\")  \n",
    "    test_images_dir  = find_images_dir(\"test\", \"test\")  \n",
    "\n",
    "    print(\"\\n Images folder:\")\n",
    "    print(f\"   train: {train_images_dir}\")\n",
    "    print(f\"   val  : {val_images_dir}\")\n",
    "    print(f\"   test : {test_images_dir}\")\n",
    "\n",
    "    # Labels folders\n",
    "    def labels_dir_from_images_dir(img_dir):\n",
    "        if img_dir and img_dir.exists():\n",
    "            labels_dir = img_dir.parent / \"labels\"\n",
    "            return labels_dir if labels_dir.exists() else None\n",
    "        return None\n",
    "\n",
    "    train_labels_dir = labels_dir_from_images_dir(train_images_dir)\n",
    "    val_labels_dir   = labels_dir_from_images_dir(val_images_dir)\n",
    "    test_labels_dir  = labels_dir_from_images_dir(test_images_dir)\n",
    "\n",
    "    print(\"\\n Labels found:\")\n",
    "    print(f\"   train: {train_labels_dir}\")\n",
    "    print(f\"   val  : {val_labels_dir}\")\n",
    "    print(f\"   test : {test_labels_dir}\")\n",
    "\n",
    "    #Image count for split\n",
    "    def count_images(folder):\n",
    "        if folder and folder.exists():\n",
    "            exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "            return sum(1 for p in folder.rglob(\"*\") if p.suffix.lower() in exts)\n",
    "        return 0\n",
    "\n",
    "    print(\"\\n Number of images in splits:\")\n",
    "    print(f\"   train: {count_images(train_images_dir)}\")\n",
    "    print(f\"   val  : {count_images(val_images_dir)}\")\n",
    "    print(f\"   test : {count_images(test_images_dir)}\")\n",
    "\n",
    "    #GPU Check\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n Current device: {device}\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(\"GPU is ready\")\n",
    "    else:\n",
    "        print(\"You're using the CPU. Go in Kaggle 'Settings' -> 'Accelerator' and select a GPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultralytics Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T09:57:20.527329Z",
     "iopub.status.busy": "2026-02-07T09:57:20.526758Z",
     "iopub.status.idle": "2026-02-07T09:58:41.918242Z",
     "shell.execute_reply": "2026-02-07T09:58:41.917487Z",
     "shell.execute_reply.started": "2026-02-07T09:57:20.527301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#We install ultralytics ignoring the depencies that we noticed were in conflict\n",
    "!pip install ultralytics==8.4.7 \"numpy<2.1.0\" --no-deps\n",
    "#Separate install for other YOLO dependencies\n",
    "!pip install ultralytics-thop pyyaml --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T09:58:48.243860Z",
     "iopub.status.busy": "2026-02-07T09:58:48.243254Z",
     "iopub.status.idle": "2026-02-07T09:58:53.487757Z",
     "shell.execute_reply": "2026-02-07T09:58:53.487024Z",
     "shell.execute_reply.started": "2026-02-07T09:58:48.243829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###Test\n",
    "import sys\n",
    "import numpy as np\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"Versione NumPy: {np.__version__}\")\n",
    "print(f\"Versione Ultralytics: {ultralytics.__version__}\")\n",
    "\n",
    "try:\n",
    "    # test model loading\n",
    "    model = YOLO(\"yolo26s.pt\") \n",
    "    print(\" Success the model is yolo26\")\n",
    "except Exception as e:\n",
    "    print(f\"Critical Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAML Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T09:59:03.722145Z",
     "iopub.status.busy": "2026-02-07T09:59:03.721699Z",
     "iopub.status.idle": "2026-02-07T09:59:03.733584Z",
     "shell.execute_reply": "2026-02-07T09:59:03.732922Z",
     "shell.execute_reply.started": "2026-02-07T09:59:03.722123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "#Looks for the dataset\n",
    "dataset_root = \"/kaggle/input/food-dataset\"\n",
    "\n",
    "\n",
    "orig_yaml = Path(f\"{dataset_root}/data.yaml\")\n",
    "with open(orig_yaml, \"r\") as f:\n",
    "    data_cfg = yaml.safe_load(f)\n",
    "\n",
    "names = data_cfg[\"names\"]\n",
    "nc = len(names)\n",
    "\n",
    "new_cfg = {\n",
    "    \"path\": dataset_root,  \n",
    "    \"train\": \"train/images\",\n",
    "    \"val\": \"valid/images\",\n",
    "    \"test\": \"test/images\",\n",
    "    \"nc\": nc,\n",
    "    \"names\": names,\n",
    "}\n",
    "\n",
    "\n",
    "out_yaml = Path(\"/kaggle/working/allergen30.yaml\")\n",
    "with open(out_yaml, \"w\") as f:\n",
    "    yaml.safe_dump(new_cfg, f, sort_keys=False)\n",
    "\n",
    "print(f\"Created YAML for YOLO26: {out_yaml}\")\n",
    "print(f\"Classe 0: {names[0]} | Total classes: {nc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T09:59:17.961476Z",
     "iopub.status.busy": "2026-02-07T09:59:17.961160Z",
     "iopub.status.idle": "2026-02-07T09:59:18.141007Z",
     "shell.execute_reply": "2026-02-07T09:59:18.140051Z",
     "shell.execute_reply.started": "2026-02-07T09:59:17.961454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training with AdamW optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T10:00:51.951664Z",
     "iopub.status.busy": "2026-02-07T10:00:51.951164Z",
     "iopub.status.idle": "2026-02-07T14:19:01.665569Z",
     "shell.execute_reply": "2026-02-07T14:19:01.664585Z",
     "shell.execute_reply.started": "2026-02-07T10:00:51.951636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO, settings\n",
    "\n",
    "#Settings reset to avoid conflicts with Ray/WandB/MLFlow\n",
    "settings.reset()\n",
    "settings.update({\n",
    "    \"raytune\": False, \n",
    "    \"wandb\": False, \n",
    "    \"mlflow\": False, \n",
    "    \"neptune\": False\n",
    "})\n",
    "\n",
    "#Loadig pre trained YOLO26\n",
    "model = YOLO(\"yolo26s.pt\")\n",
    "\n",
    "#No AMP to avoid crashing\n",
    "results = model.train(\n",
    "    data=\"/kaggle/working/allergen30.yaml\",\n",
    "    epochs=100,\n",
    "    patience=25,\n",
    "    imgsz=416,\n",
    "    batch=32,\n",
    "    workers=2,\n",
    "    amp=False,          \n",
    "    \n",
    "#AdamW Hyperparameters     \n",
    "    optimizer='AdamW',    \n",
    "    lr0=0.001,             \n",
    "    cos_lr=True,           \n",
    "    label_smoothing=0.1,   \n",
    "    mosaic=1.0,            \n",
    "    mixup=0.15,\n",
    "    weight_decay=0.0005, \n",
    "    #\n",
    "    \n",
    "    device=0,\n",
    "    name=\"yolo26s_allergeni_TUNED\",\n",
    "    project=\"allergen_project\",\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Confusion Matrix and various plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T14:25:50.839475Z",
     "iopub.status.busy": "2026-02-07T14:25:50.839181Z",
     "iopub.status.idle": "2026-02-07T14:25:52.472959Z",
     "shell.execute_reply": "2026-02-07T14:25:52.472137Z",
     "shell.execute_reply.started": "2026-02-07T14:25:50.839458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#results path\n",
    "results_dir = \"/kaggle/working/runs/detect/allergen_project/yolo26s_allergeni_TUNED2\"\n",
    "\n",
    "#Graphs (Loss, Precision, Recall, mAP)\n",
    "results_png = os.path.join(results_dir, \"results.png\")\n",
    "if os.path.exists(results_png):\n",
    "    img = cv2.imread(results_png)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Training: Loss and Metrics (P, R, mAP)\", fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "#Confusion Matrix\n",
    "conf_matrix = os.path.join(results_dir, \"confusion_matrix.png\")\n",
    "if os.path.exists(conf_matrix):\n",
    "    img_cm = cv2.imread(conf_matrix)\n",
    "    img_cm = cv2.cvtColor(img_cm, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img_cm)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Confusion Matrix\", fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T14:25:57.768810Z",
     "iopub.status.busy": "2026-02-07T14:25:57.768531Z",
     "iopub.status.idle": "2026-02-07T14:26:10.596337Z",
     "shell.execute_reply": "2026-02-07T14:26:10.595442Z",
     "shell.execute_reply.started": "2026-02-07T14:25:57.768790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Loading best weights\n",
    "model_trained = YOLO(f\"{results_dir}/weights/best.pt\")\n",
    "\n",
    "#Validation on test set\n",
    "metrics = model_trained.val(split='test')\n",
    "\n",
    "print(\"\\n--- Final Performance on Test Set ---\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export of the best weights in ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T14:28:08.046733Z",
     "iopub.status.busy": "2026-02-07T14:28:08.045894Z",
     "iopub.status.idle": "2026-02-07T14:28:14.930432Z",
     "shell.execute_reply": "2026-02-07T14:28:14.929821Z",
     "shell.execute_reply.started": "2026-02-07T14:28:08.046704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Loads the trained model\n",
    "model = YOLO(\"/kaggle/working/runs/detect/allergen_project/yolo26s_allergeni_TUNED2/weights/best.pt\")\n",
    "\n",
    "#ONNX Export for the app\n",
    "path = model.export(format=\"onnx\", imgsz=640, opset=17, simplify=True)\n",
    "\n",
    "print(f\"ONNX model reday for download: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check of uploaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T14:26:46.462898Z",
     "iopub.status.busy": "2026-02-07T14:26:46.462640Z",
     "iopub.status.idle": "2026-02-07T14:27:01.722465Z",
     "shell.execute_reply": "2026-02-07T14:27:01.721515Z",
     "shell.execute_reply.started": "2026-02-07T14:26:46.462881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "pt_files = glob.glob(\"/kaggle/input/**/*.pt\", recursive=True)\n",
    "\n",
    "print(\"Found weights files:\")\n",
    "for file in pt_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moves uploaded model in kaggle working area then patches it and exports it for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T14:28:28.698156Z",
     "iopub.status.busy": "2026-02-07T14:28:28.697823Z",
     "iopub.status.idle": "2026-02-07T14:28:31.280245Z",
     "shell.execute_reply": "2026-02-07T14:28:31.279120Z",
     "shell.execute_reply.started": "2026-02-07T14:28:28.698126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import copy\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "source_path = \"/kaggle/input/bestyolos/pytorch/default/1/best.pt\"\n",
    "writable_path = \"best.pt\"\n",
    "\n",
    "print(f\"Copying from {source_path} to {writable_path}...\")\n",
    "shutil.copy(source_path, writable_path)\n",
    "\n",
    "\n",
    "print(\"--- STARTING YOLO26 COMPATIBILITY EXPORT ---\")\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "internal_model = model.model\n",
    "\n",
    "#Patching the ARGS\n",
    "print(\"Patching internal configuration...\")\n",
    "if hasattr(internal_model, 'args'):\n",
    "    args = internal_model.args\n",
    "    if isinstance(args, dict):\n",
    "        args['end2end'] = False\n",
    "        args['nms'] = False\n",
    "        print(\"settings patched: end2end=False\")\n",
    "    else:\n",
    "        args.end2end = False\n",
    "        args.nms = False\n",
    "        print(\" settings patched: end2end=False\")\n",
    "\n",
    "# Check if the patch worked\n",
    "for m in internal_model.modules():\n",
    "    if hasattr(m, 'end2end'):\n",
    "        print(f\"Detect Head status: end2end={m.end2end}\") \n",
    "        #force-override the class property below \n",
    "        if m.end2end == True:\n",
    "            print(\" Property is locked. Applying Nuclear Patch...\")\n",
    "            type(m).end2end = property(lambda self: False) # Force it to return False\n",
    "            print(f\"Nuclear Patch applied. New status: {m.end2end}\")\n",
    "\n",
    "#Prepare for export\n",
    "internal_model.eval()\n",
    "dummy_input = torch.randn(1, 3, 640, 640)\n",
    "\n",
    "#Export directly with PYtorch\n",
    "print(\"Exporting via torch.onnx (Bypassing YOLO Exporter)...\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    internal_model,\n",
    "    dummy_input,\n",
    "    \"final_model.onnx\",\n",
    "    opset_version=12,\n",
    "    input_names=['images'],\n",
    "    output_names=['output0'],\n",
    "    dynamic_axes=None \n",
    ")\n",
    "\n",
    "print(\"--- SUCCESS ---\")\n",
    "print(\"Download 'final_model.onnx'. This is the one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final plots and Comparison of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T14:29:42.371335Z",
     "iopub.status.busy": "2026-02-07T14:29:42.370567Z",
     "iopub.status.idle": "2026-02-07T14:29:43.831531Z",
     "shell.execute_reply": "2026-02-07T14:29:43.830680Z",
     "shell.execute_reply.started": "2026-02-07T14:29:42.371309Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "data = {\n",
    "    'Model': ['Nano', 'Small', 'Medium'],\n",
    "    \n",
    "    'mAP50': [0.7301, 0.7691, 0.7465], \n",
    "    \n",
    "    'mAP50-95': [0.5347, 0.5726, 0.5740],\n",
    "    \n",
    "    'Precision': [0.8226, 0.8352, 0.8376],\n",
    "    \n",
    "    'Recall': [0.6362, 0.6636, 0.6405]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#f1 computing\n",
    "df['F1_Score'] = 2 * (df['Precision'] * df['Recall']) / (df['Precision'] + df['Recall'])\n",
    "\n",
    "print(\"--- MODEL PERFORMANCE TABLE ---\")\n",
    "display(df.round(4))\n",
    "\n",
    "#colmuns plots\n",
    "\n",
    "df_melted = df.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "chart = sns.barplot(x=\"Metric\", y=\"Score\", hue=\"Model\", data=df_melted, palette=\"viridis\")\n",
    "\n",
    "for container in chart.containers:\n",
    "    chart.bar_label(container, fmt='%.2f', padding=3)\n",
    "\n",
    "plt.title(\"Model Comparison: Nano vs Small vs Medium\", fontsize=16, weight='bold')\n",
    "plt.ylim(0, 1.0) # Fix y-axis from 0 to 1\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#radar plot\n",
    "\n",
    "labels = list(df.columns[1:]) \n",
    "num_vars = len(labels)\n",
    "\n",
    "angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
    "angles += angles[:1] \n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "plt.xticks(angles[:-1], labels)\n",
    "\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c'] \n",
    "for i, row in df.iterrows():\n",
    "    values = row[1:].tolist()\n",
    "    values += values[:1] \n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=row['Model'], color=colors[i])\n",
    "    ax.fill(angles, values, color=colors[i], alpha=0.1)\n",
    "\n",
    "plt.title(\"Model Trade-off Analysis (Radar Chart)\", size=15, weight='bold', y=1.1)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8951283,
     "sourceId": 14063262,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 572993,
     "modelInstanceId": 560406,
     "sourceId": 735159,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
